---
layout: post
title:  "Heap Sort"
date:   2020-05-16
tags: Sorting Tree Heap
mathjax: true
---

Since heap sort has a lot more to cover, I broke down the content so that it will be easier for user to browse.

[Table of Content](2020-05-16-Heap-Sort.md)
- [1. Binary Heap - Data Structure](#1-binary-heap---data-structure)
- [2. Maintaining the Heap Property (Max-Heap)](#2-maintaining-the-heap-property-max-heap)
- [3. Building a Heap](#3-building-a-heap)
- [4. Heapsort](#4-heapsort)

### 1. Binary Heap - Data Structure
A binary heap is a specialized *binary tree-based* data structure which is essentially an ***almost complete tree*** that satisfies the binary heap property. There are two types of binary heaps, max-heaps and min-heaps.
> A **Complete Tree** is a binary tree in which every level, except possibly the last, is completely filled, and all nodes are as far left as possible. ***A complete tree must be a balanced tree***.
> 
> **Max Heap Property**: for every node $i$, other than the root, $A[Parent(i)] \geq A[i]$, that is, the value of a node is at most the value of its parent. Thus, the largest element in a max-heap is stored at the root, and the subtree rooted at a node contains values no larger than that contained at the node itself.
>
> **Min Heap Property**: Conversely, for every node $i$ other than the root, $A[Parent(i)] \leq A[i]$. The smallest element in a min-heap is at the root.

Due to its complete tree property, each node of the tree corresponds to an element of the array. Thus, We have the following conversion between array index and heap.
{% highlight java linenos %}
// i is the index in the array
PARENT(i):
  return floor(i/2)
LEFT(i):
  return 2*i + 1
RIGHT(i):
  return 2*i + 2
{% endhighlight %}

A more detailed example can be seen in the figure below.
<figure>
    <img src="https://zl323.github.io/assets/postImg/maxheap.png" alt="useful image" height="100%" width="100%">
    <figcaption>Credit to Introduction to Algorithm by Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein</figcaption>
</figure>

> Viewing a heap as tree, we define the height of a node in a heap to be number of edges on the longest simple downward path from the node to a leaf, and we define the height of the heap to be the height of its root. Since a heap of n elements is based on complete tree, its height is $\lfloor{logn}\rfloor$.

### 2. Maintaining the Heap Property (Max-Heap)
To preserve the heap property, we need to do MAX_HEAPIFY everytime we insert additional node into the heap. Here is the pseudocode for MAX_HEAPIFY: 

{% highlight java linenos %}
// n: heap size, not array size
// i: index of current node
MAX_HEAPIFY(A, i, n):
  largest = i
  l = LEFT(i)
  r = RIGHT(i)
  // compare left and right child with parent and see which one is the largest
  if(l < n and A[l] > A[largest]) 
    largest = l
  if(r < n and A[r] > A[largest])
    largest = r
  // if the largest lies in left/right child, swap it with the parent node
  // continue doing recursion
  if(largest != i)
    swap(A, i, largest)
    MAX_HEAPIFY(A, largest, n)
{% endhighlight %}

Let's analyze the runtime of MAX_HEAPIFY method. Comparison among A[LEFT(i)], A[RIGHT(i)] and PARENT A[i] takes $O(1)$. The recursion cost in the MAX_HEAPIFY depends on the height of the binary tree. In the worst case, the childrenâ€™s subtrees each have size at most $\frac{2n}{3}$. In other words, the worst case occurs when the bottom level of the tree is exactly half full.

***Think: Why does the worst case happen when the bottom level of the tree is exactly half full? Where does $\frac{2n}{3}$ come from?***
<details>
<summary>answer</summary>
Let's prove this theory. As we have mentioned above, a complete tree is also a balanced tree. Therefore, the largest difference between the left and right subtrees occurs when the bottom level of left subtree is full, while the bottom level of right subtree is empty. In other words, the left subtree is deeper than right subtree by 1.
<p>
If we set the height of left subtree is $h$, then the left subtree has $2^h-1$ number of elements. The right subtree has $2^{h-1}-1$ number of elements.

$$ltree\_count = 2^h-1$$
$$rtree\_count = 2^{h-1}-1$$
$$rtree\_count = \frac{1}{2}ltree\_count - \frac{1}{2}$$
Therefore, we can get:
$$ltree\_count + rtree\_count + 1(root) = \frac{3}{2}ltree\_count + \frac{1}{2} = n$$
where $n$ is the total number of nodes in the tree
$$ltree\_count = \frac{2}{3}(n-\frac{1}{2}) \leq \frac{2}{3}n$$
</p>
</details>

Therefore, the runtime cost by recursion in MAX_HEAPIFY is:
\\[
T(n) \leq T(\frac{2n}{3}) + T(1)
\\]
We can conclude that $T(n) = O(logn)$, or $O(h)$, where $h$ is the height of tree, which is the overall runtime of MAX_HEAPIFY.

Notice that this method MAX_HEAPIFY has another name called PrelocateDown. This is because everytime we move parent node down towards the bottom if it is smaller than both left and right children to make sure parent node is always greater than its children. We will discuss more in the detailed implementation blog of max-heap in Java.

### 3. Building a Heap
As we know how to preserve the heap property, building a heap is more straightfoward. Let's take a look at the pseudocode of Build-Max-Heap.

{% highlight java linenos %}
BUILD_MAX_HEAP(A, n):
  for i = floor(n/2) downto 0
    MAX_HEAPIFY(A,i,n)
{% endhighlight %}

The reason why we only loop the first half of the array is because elements in the second half of array are all leaf nodes. There is no need to heapify them. And we loop starting from $\lfloor{A.length/2}\rfloor$ is because we build max-heap from bottom to the top. The figure below gives the example.

<figure>
    <img src="https://zl323.github.io/assets/postImg/buildMaxHeap.png" alt="useful image" height="100%" width="100%">
    <figcaption>Credit to Introduction to Algorithm by Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein</figcaption>
</figure>

BUILD_MAX_HEAP method has a cost of $O(nlogn)$ runtime, since we loop MAX_HEAPIFY $n$ times, each time costs $O(logn)$.

### 4. Heapsort
Finally, we can write Heapsort! Here is the pseudocode:

{% highlight java linenos %}
HEAPSORT(A, n):
  BUILD_MAX_HEAP(A, n)         // build max-heap
  for i = n downto 0
    swap(A, 0, i)              // A[0] always holds the max number in the heap
    MAX_HEAPIFY(A, 0, i)       // maintain max-heap property, note that we parse the heapSize i instead of arrayLength n
  return A
{% endhighlight %}

When we call MAX_HEAPIFY in the heapSort method, notice that we parse current heapSize $i$. As we sort max number in the right position, the size of unsorted number in the heap should be decreased. A more detailed figure can be seen below:

<figure>
    <img src="https://zl323.github.io/assets/postImg/heapSort.png" alt="useful image" height="100%" width="100%">
    <figcaption>Credit to Introduction to Algorithm by Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein</figcaption>
</figure>
As the grey nodes are being sorted into the right position in the array, the size of heap is decreasing. That's why we parse $i$.

Similarly heapsort has overall runtime of $O(nlogn)$. Since we don't use extra space, the space complexity is $O(1)$. Last but not least, heapsort is ***UNSTABLE***.

> Note: Detailed implementation of Max-Heap can be found in this post.